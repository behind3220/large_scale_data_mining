{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyTXGbkAkE8A"
   },
   "source": [
    "# Module loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyZ_jnA1dzst"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import string\n",
    "from string import punctuation\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.metrics import auc, roc_curve, plot_roc_curve, plot_confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import datasets, metrics, model_selection, svm\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tempfile import mkdtemp\n",
    "from joblib import Memory\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = !pwd\n",
    "data_path = str(pwd[0]) + '/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEx_s_txFDjn"
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVSIOAmnpJoY",
    "outputId": "9d37a14d-b943-42d3-ba1a-9e56c6e65737"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJKwHBc3GK0F"
   },
   "source": [
    "### How many rows (samples) and columns (features) are present in the dataset?\n",
    "- There are 3150 rows and 8 features presented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Cy0b2Dv9HeF",
    "outputId": "5cfea26b-21bc-4dcf-d513-129a53ced2db"
   },
   "outputs": [],
   "source": [
    "df['totalwords'] = df['full_text'].str.split().str.len()\n",
    "df['totalwords'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFMw6QXFn71o"
   },
   "source": [
    "### The total number of alpha-numeric characters per data point (row) in the feature full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "gsMbDxTq0j_4",
    "outputId": "938a87ee-db1e-4750-9802-e0959283b1ef"
   },
   "outputs": [],
   "source": [
    "# (a) The total number of alpha-numeric characters per data point (row) in the feature full text\n",
    "figsize(9,5)\n",
    "nparr=df['totalwords'].to_numpy()\n",
    "values, counts = np.unique(nparr, return_counts=True)\n",
    "plt.bar(values,counts, color='blue', edgecolor = 'black')\n",
    "plt.ylabel('frequencies')\n",
    "plt.xlabel('counts')\n",
    "plt.title('The total number of alpha-numeric characters per data point (row) in the feature full text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6mnhrpdoD8L"
   },
   "source": [
    "### The column leaf label – class on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "2rL6-Xo4IAjI",
    "outputId": "f7029cd1-b7b9-4f6d-e577-79f9d7601756"
   },
   "outputs": [],
   "source": [
    "#(b) The column leaf label – class on the x-axis\n",
    "nparr=df['leaf_label'].to_numpy()\n",
    "values, counts = np.unique(nparr, return_counts=True)\n",
    "figsize(12,5)\n",
    "\n",
    "plt.bar(values,counts, color='blue', edgecolor = 'black')\n",
    "plt.ylabel('frequencies')\n",
    "plt.xlabel('counts')\n",
    "plt.title('With column leaf label on the x-axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDMnuS7MoSga"
   },
   "source": [
    "### The column root label – class on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "2D8ESlwQJniN",
    "outputId": "016166e6-4459-47ae-b004-b5af7f1b8133"
   },
   "outputs": [],
   "source": [
    "#(c) The column root label – class on the x-axis.\n",
    "#• Interpret Plots: Provide qualitative interpretations of the histograms.\n",
    "nparr=df['root_label'].to_numpy()\n",
    "values, counts = np.unique(nparr, return_counts=True)\n",
    "figsize(12,5)\n",
    "\n",
    "plt.bar(values,counts, color='blue', edgecolor = 'black')\n",
    "plt.ylabel('frequencies')\n",
    "plt.xlabel('counts')\n",
    "plt.title('With column root label on the x-axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUpeSUrbUDHJ"
   },
   "source": [
    "### Qualitative interpretations:\n",
    "- From the above graphs, we conclude that while we have an equal number of samples(rows) for each leaf sample.\n",
    "- On the other hand, there's a slight difference between the number of samples for the columns of root label, which stems from the root label \"sports\" having one extra leaf label.\n",
    "- Another observation is that the variance of word counts between different samples is quite high, with some outliers at over 7000 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8847z5c_S1E"
   },
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XC7l-N_Gwdsg",
    "outputId": "aefc6f1e-c71c-411b-e2b8-9d102baf342c"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df[[\"full_text\",\"root_label\"]], test_size=0.2)\n",
    "#checking text after cleaning\n",
    "train['full_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnr9lQCgfQ_y",
    "outputId": "ba55e5bc-9f12-46cd-e995-185bdee1eaaa"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "#define cleaning function\n",
    "def clean(text):\n",
    " text = re.sub (r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    " texter = re.sub(r\"<br />\", \" \", text)\n",
    " texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
    " texter = re.sub('&#39;', \"\\\"\", texter)\n",
    " texter = re.sub('\\n', \" \", texter)\n",
    " texter = re.sub(' u ',\" you \", texter)\n",
    " texter = re.sub('`',\"\", texter)\n",
    " texter = re.sub(' +', ' ', texter)\n",
    " texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
    " texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
    " texter = re.sub('&amp;', 'and', texter)\n",
    " texter = re.sub('\\r', ' ',texter)\n",
    " clean = re.compile('<.*?>')\n",
    " texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
    " texter = re.sub(clean, '', texter)\n",
    " if texter == \"\":\n",
    "  texter = \"\"\n",
    " return texter\n",
    "\n",
    "#clean raw text\n",
    "for i in df['full_text']:\n",
    "  clean(i)\n",
    "df['full_text'] = df['full_text'].str.replace('\\d+', '') # for digits\n",
    "df['full_text'] = df['full_text'].str.replace('[^\\w\\s]', '') # for punctuation \n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Training samples size:\", train.shape)\n",
    "print(\"Testing samples size:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0vpgNqI2Al0"
   },
   "source": [
    "### Report the number of training and testing samples.\n",
    "\n",
    "A:\n",
    "\n",
    "The training samples contain 2520 rows and 2 features.\n",
    "\n",
    "The testing samples contain 630 rows and 2 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w458du9tgCj3"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zua9_XJ1fe0o"
   },
   "outputs": [],
   "source": [
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "def lemmatize_sent(text): \n",
    "    # Text input is string.\n",
    "    # Returns sequence of lowercased strings(words).\n",
    "    lemma_list = []\n",
    "    lemma_list = [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "    # Turn array of strings into sequence\n",
    "    return ' '.join(lemma_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MlRcms9fphx",
    "outputId": "d164e838-86af-420e-9caf-35a94aa77497"
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "vec = CountVectorizer(stop_words='english', min_df=3)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "X_train_lemma = []\n",
    "X_test_lemma = []\n",
    "for i in range(len(train)):\n",
    "  # print(lemmatize_sent(train.iloc[i]['full_text']))\n",
    "  X_train_lemma.append(lemmatize_sent(train.iloc[i]['full_text']))\n",
    "for i in range(len(test)):\n",
    "  X_test_lemma.append(lemmatize_sent(test.iloc[i]['full_text']))\n",
    "\n",
    "X_train_vec = vec.fit_transform(X_train_lemma)\n",
    "X_test_vec = vec.transform(X_test_lemma)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_vec)\n",
    "X_test_tfidf = tfidf.transform(X_test_vec)\n",
    "print(\"X_train shape:\", X_train_tfidf.shape)\n",
    "print(\"X_test shape:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBDB7VB5tFWn"
   },
   "source": [
    "### What are the pros and cons of lemmatization versus stemming? How do these processes affect the dictionary size?\n",
    "\n",
    "A: \n",
    "The main advantage of lemmatization is that it takes into consideration the context of the word to determine which is the intended meaning the user is looking for. This process allows to decrease noise and speed up the user’s task. However,because lemmatization involves deriving the meaning of a word from something like a dictionary, it's very time consuming.\n",
    "\n",
    "Stemming usually refers to a process of chopping off the last few characters. Stemming operates on a single word without knowledge of the context. Stemming is not a well-defined process, it often suffers from incorrect meaning and spelling errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOFZxsiqtn6I"
   },
   "source": [
    "### min df means minimum document frequency. How does varying min df change the TF-IDF matrix?\n",
    "\n",
    "A: \n",
    "\n",
    "When we increase the min df, it will decrease the column counts of the matrix, because the goal of MIN_DF is to ignore words that have very few occurrences to be considered meaningful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q97b28tLtzk0"
   },
   "source": [
    "### Should I remove stopwords before or after lemmatizing? Should I remove punctuations before or after lemmatizing? Should I remove numbers before or after lemmatizing?\n",
    "\n",
    "A: \n",
    "\n",
    "We should remove stopwords after lemmatizing but remove punctuations before lemmatizing. Because in certain cases, stop words do indeed contribute meaning, and if an application is sensitive to such meanings, then stop words should not be eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6V-DEMSuMYI"
   },
   "source": [
    "### Report the shape of the TF-IDF-processed train and test matrices. The number of rows should match the results of Question 2. The number of columns should roughly be in the order of $k × 10^3 $.\n",
    "\n",
    "A: \n",
    "\n",
    "The train matrices contains 2520 rows and 14224 columns and the test set contains 630 rows and 14224 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb1X9ZHWgGw0"
   },
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "id": "XKreW79Qfzwy",
    "outputId": "12f0bae1-5a86-42ae-cb67-41634cc6fc7b"
   },
   "outputs": [],
   "source": [
    "ks = [1, 10, 50, 100, 200, 500, 1000, 2000]\n",
    "ratios = []\n",
    "for i in range(len(ks)):\n",
    "  svd_tmp = TruncatedSVD(n_components=ks[i], random_state=42)\n",
    "  # print(svd_tmp.explained_variance_ratio_)\n",
    "  svd_tmp.fit(X_train_tfidf)\n",
    "  print(\"explained_variance_ratio when k =\", ks[i], \":\", svd_tmp.explained_variance_ratio_.sum())\n",
    "  ratios.append(svd_tmp.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(ks, ratios)\n",
    "\n",
    "ax.set_ylabel('explained_variance_ratio')\n",
    "ax.set_xlabel('k')\n",
    "plt.title('explained_variance_ratio versus different k')\n",
    "plt.show()\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "nmf = NMF(n_components=50, init='random', random_state=42)\n",
    "\n",
    "print(\"\\n\")\n",
    "# LSI\n",
    "X_train_LSI = svd.fit_transform(X_train_tfidf)\n",
    "X_test_LSI = svd.transform(X_test_tfidf)\n",
    "# NMF\n",
    "X_train_NMF = nmf.fit_transform(X_train_tfidf)\n",
    "X_test_NMF = nmf.transform(X_test_tfidf)\n",
    "# W = X_test_xxx\n",
    "# H = nmf.components_\n",
    "\n",
    "# data shape\n",
    "print(\"LSI:\")\n",
    "print('training data shape = ', X_train_LSI.shape)\n",
    "print('test data shape = ', X_test_LSI.shape)\n",
    "print(\"NMF:\")\n",
    "print('training data shape = ', X_train_NMF.shape)\n",
    "print('test data shape = ', X_test_NMF.shape)\n",
    "\n",
    "\n",
    "# calculate the reconstruction residual MSE error\n",
    "train_U, train_S, train_V = randomized_svd(X_train_tfidf, n_components=50, random_state=42)\n",
    "test_U, test_S, test_V = randomized_svd(X_test_tfidf, n_components=50, random_state=42)\n",
    "print(\"\\n\")\n",
    "print(\"the reconstruction residual MSE error:\")\n",
    "print(\"When using LSI:\")\n",
    "print('training error:',np.sum(np.array(X_train_tfidf - (train_U.dot(np.diag(train_S)).dot(train_V)))**2))\n",
    "print('test error:',np.sum(np.array(X_test_tfidf - (test_U.dot(np.diag(test_S)).dot(test_V)))**2))\n",
    "\n",
    "print(\"When using NMF:\")\n",
    "print('training error:',np.sum(np.array(X_train_tfidf - X_train_NMF.dot(nmf.components_))**2))\n",
    "print('test error:',np.sum(np.array(X_test_tfidf - X_test_NMF.dot(nmf.components_))**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjLAvq_ohZOz"
   },
   "source": [
    "### What does the explained variance ratio plot look like? What does the plot’s concavity suggest?\n",
    "\n",
    "A:\n",
    "\n",
    "The plot looks like a concave down durve. As k increases, the explained variance ratio getting larger. In which makes sense since the ratio reflects how much variation of the target value(Y) is explained by the data features(X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jV3FiRH5QKo"
   },
   "source": [
    "### With k = 50 found in the previous sections, calculate the reconstruction residual MSE error when using LSI and NMF – they both should use the same k = 50. Which one is larger, the $∥X − WH∥_2^F$ in NMF or the $∥X − U_kΣ_kV^T_k∥^F_2$ in LSI and why?\n",
    "\n",
    "A:\n",
    "\n",
    "As you can see, both the training error and test error in NMF are larger than those in LSI. \n",
    "\n",
    "It makes sense because LSI is a more insightful method by giving us more information with the SVD factorization. Therefore, its mse error will be lower than NMF as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p2F9GLNWb0c"
   },
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72SW7fygYFGB"
   },
   "outputs": [],
   "source": [
    "map_root = {\"sports\":1, \"climate\":0}\n",
    "y_train = train['root_label'].map(map_root)\n",
    "y_test = test['root_label'].map(map_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trD6DkoUsai1"
   },
   "outputs": [],
   "source": [
    "def print_roc_curve(X_test_LSI, y_test, model, plt_title, colar):\n",
    "  fig, ax = plt.subplots()\n",
    "  plot_roc_curve(model, X_test_LSI, y_test, ax=ax, color=colar)\n",
    "  ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.5)\n",
    "  plt.title(plt_title)\n",
    "  plt.show()\n",
    "\n",
    "def print_cf_matrix(X_test_LSI, y_test, model, plt_title, display_labels):\n",
    "  plot_confusion_matrix(model, X_test_LSI, y_test, display_labels=display_labels)\n",
    "  plt.tight_layout()\n",
    "  plt.title(plt_title)\n",
    "  # plt.savefig(image_name)\n",
    "  plt.show()\n",
    "\n",
    "def print_result(model_title, y_test, y_pred):\n",
    "  print(model_title, \":\")\n",
    "  print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "def print_multi_result(model_title, y_test, y_pred):\n",
    "  print(model_title, \":\")\n",
    "  print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred, average='weighted'), \"\\n\")\n",
    "\n",
    "root_labels = ['climate', 'sports']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MQnWLIrbsLr"
   },
   "source": [
    "### Train one SVM with γ = 1000 (hard margin), another with γ = 0.0001 (soft margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvgWwWWcvvw_"
   },
   "outputs": [],
   "source": [
    "# build the svm with given gamma\n",
    "hard_svm = svm.SVC(kernel='linear', C=1000, random_state=42)\n",
    "soft_svm = svm.SVC(kernel='linear', C=0.0001, random_state=42)\n",
    "harder_svm = svm.SVC(kernel='linear', C=100000, random_state=42)\n",
    "\n",
    "# fit the model\n",
    "hard_svm.fit(X_train_LSI, y_train)\n",
    "soft_svm.fit(X_train_LSI, y_train)\n",
    "harder_svm.fit(X_train_LSI, y_train)\n",
    "\n",
    "# predict the test data\n",
    "hard_y_pred = hard_svm.predict(X_test_LSI)\n",
    "soft_y_pred = soft_svm.predict(X_test_LSI)\n",
    "harder_y_pred = harder_svm.predict(X_test_LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15LcOSFYbwXp"
   },
   "source": [
    "###  Plot the ROC curve, report the confusion matrix and calculate the accuracy, recall, precision and F-1 score of both SVM classifiers on the testing set. Which one performs better? What about for γ = 100000?\n",
    "\n",
    "A:\n",
    "\n",
    "As you can find in the following sections, the hard margin one performs better in this dataset. And the one with γ = 100000 performs even better than the hard margin one a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0gWtKWWWs5HJ",
    "outputId": "6bd9c5af-443c-474d-9812-f512f1e8fb1c"
   },
   "outputs": [],
   "source": [
    "print_roc_curve(X_test_LSI, y_test, hard_svm, 'ROC curve for the hard margin SVM', 'b')\n",
    "print_roc_curve(X_test_LSI, y_test, soft_svm, 'ROC curve for the soft margin SVM', 'g')\n",
    "print_roc_curve(X_test_LSI, y_test, harder_svm, 'ROC curve for the SVM with gamma = 100000', 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zuh6qi8l_1PL",
    "outputId": "d00751ae-2c38-4cd3-853c-51b0cdc55163"
   },
   "outputs": [],
   "source": [
    "print_cf_matrix(X_test_LSI, y_test, hard_svm, 'Hard SVM', display_labels=root_labels)\n",
    "print_cf_matrix(X_test_LSI, y_test, soft_svm, 'Soft SVM', display_labels=root_labels)\n",
    "print_cf_matrix(X_test_LSI, y_test, harder_svm, 'SVM with gamma = 100000', display_labels=root_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "634dmPHhA4ex",
    "outputId": "b45ee734-a6f9-4d0a-edaf-c5489dc173b9"
   },
   "outputs": [],
   "source": [
    "print_result(\"Hard SVM\", y_test, hard_y_pred)\n",
    "print_result(\"Soft SVM\", y_test, soft_y_pred)\n",
    "print_result(\"SVM with gamma = 100000\", y_test, harder_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUnR87-6ce79"
   },
   "source": [
    "### What happens for the soft margin SVM? Why is the case? Analyze in terms of the confusion matrix\n",
    "\n",
    "A:\n",
    "\n",
    "From the confusion matrix of soft margin SVM, you can find that it predicts all the test data into the \"sports\" category. In which might because of its margin is too small to allow the model classify different data and makes the misclassification of data not being punished.\n",
    "\n",
    "#### Does the ROC curve reflect the performance of the soft-margin SVM? Why?\n",
    "\n",
    "A:\n",
    "\n",
    "No. It doesn't reflect the performance.\n",
    "\n",
    "The ROC curve is a plot of True Positive Rate (TPR) on the y-axis vs. False Positive Rate (FPR) on the x-axis.\n",
    "\n",
    "$TPR = \\frac{True Positive}{True Positive + False Negative}$\n",
    "\n",
    "$FPR = \\frac{False Positive}{False Positive + True Negative}$\n",
    "\n",
    "Since the model predicts all the test data into the \"sports\" label, you can find out that the TPR and FPR are all **equal to 1** in this situation.\n",
    "Therefore, the ROC curve is not useful to evaluate the performance of the soft-margin SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbfDs0fph3to"
   },
   "source": [
    "### Use cross-validation to choose γ (use average validation 3 accuracy to compare): Using a 5-fold cross-validation, find the best value of the parameter γ in the range {10k | − 3 ≤ k ≤ 6, k ∈ Z}. Again, plot the ROC curve and report the confusion matrix and calculate the accuracy, recall precision and F-1 score of this best SVM.\n",
    "\n",
    "After using the cross-validation, we can find out the best γ to use here is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4PJrFIOJFIA"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(random_state=42)\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000], 'kernel': ['linear']}\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, cv=5, scoring='accuracy')\n",
    "clf.fit(X_train_LSI, y_train)\n",
    "best_y_pred = clf.best_estimator_.predict(X_test_LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h8NUvECdKHry",
    "outputId": "50854ac1-e0cb-4a55-e4bc-9c2a6b50cafe"
   },
   "outputs": [],
   "source": [
    "print('Best Value of γ:',clf.best_params_['C']) \n",
    "for l, n in zip(parameters['C'], clf.cv_results_['mean_test_score']):\n",
    "    print(f'γ: {l}\\t',f'average validation accuracy: {n}')\n",
    "print_roc_curve(X_test_LSI, y_test, clf.best_estimator_, 'ROC curve for the BEST SVM', 'b')\n",
    "print_cf_matrix(X_test_LSI, y_test, clf.best_estimator_, 'BEST SVM', display_labels=root_labels)\n",
    "print_result(\"BEST SVM\", y_test, best_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMjBB3ThLSxK"
   },
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1wp-SVniZs_"
   },
   "source": [
    "### Train a logistic classifier without regularization (you may need to come up with some way to approximate this if you use sklearn.linear model.LogisticRegression); plot the ROC curve and report the confusion matrix and calculate the accuracy, recall precision and F-1 score of this classifier on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgMlE1xUMBij"
   },
   "outputs": [],
   "source": [
    "log_wor = LogisticRegression(penalty='none', random_state=9527, max_iter=100000)\n",
    "log_wor.fit(X_train_LSI, y_train)\n",
    "log_wor_y_pred = log_wor.predict(X_test_LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "o8is-mzwEpe7",
    "outputId": "5617c199-8d43-47b3-b77f-2d006cc86136"
   },
   "outputs": [],
   "source": [
    "print_roc_curve(X_test_LSI, y_test, log_wor, 'ROC curve for the Logistic Regression without regularization', 'b')\n",
    "print_cf_matrix(X_test_LSI, y_test, log_wor, 'Logistic Regression without regularization', display_labels=root_labels)\n",
    "print_result(\"Logistic Regression without regularization\", y_test, log_wor_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5JnuFVOilYs"
   },
   "source": [
    "### Using 5-fold cross-validation on the dimension-reduced-by-SVD training data, find the optimal regularization strength in the range {10k | −5 ≤ k ≤ 5, k ∈ Z} for logistic regression with L1 regularization and logistic regression with L2 regularization, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6w0TgXAN0T2"
   },
   "outputs": [],
   "source": [
    "# L1 regularization\n",
    "log_l1 = LogisticRegression(penalty='l1', random_state=9527, solver='liblinear', max_iter=100000)\n",
    "parameters = {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\n",
    "clf_l1 = GridSearchCV(log_l1, parameters, cv=5, scoring='accuracy')\n",
    "clf_l1.fit(X_train_LSI, y_train)\n",
    "l1_best_y_pred = clf_l1.best_estimator_.predict(X_test_LSI)\n",
    "# L2 regularization\n",
    "log_l2 = LogisticRegression(penalty='l2', random_state=9527, solver='liblinear', max_iter=100000)\n",
    "parameters = {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}\n",
    "clf_l2 = GridSearchCV(log_l2, parameters, cv=5, scoring='accuracy')\n",
    "clf_l2.fit(X_train_LSI, y_train)\n",
    "l2_best_y_pred = clf_l2.best_estimator_.predict(X_test_LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVd8qRt-izYP"
   },
   "source": [
    "### Compare the performance (accuracy, precision, recall and F-1 score) of 3 logistic classifiers: w/o regularization, w/ L1 regularization and w/ L2 regularization (with the best parameters you found from the part above), using test data.\n",
    "\n",
    "A:\n",
    "\n",
    "When using the best parameter we found, we can find that we get the exact same performance of 3 different logistic classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FV8jCHu1PV5t",
    "outputId": "5cd265d1-3724-4267-b5ae-8501685024c1"
   },
   "outputs": [],
   "source": [
    "print('Best Value of regularization strength in L1 regularization:',clf_l1.best_params_['C']) \n",
    "for l, n in zip(parameters['C'], clf_l1.cv_results_['mean_test_score']):\n",
    "    print(f'reg. strength(C):{l}\\t',f'average validation accuracy: {n}')\n",
    "\n",
    "print('\\nBest Value of regularization strength in L2 regularization:',clf_l2.best_params_['C']) \n",
    "for l, n in zip(parameters['C'], clf_l2.cv_results_['mean_test_score']):\n",
    "    print(f'reg. strength(C):{l}\\t',f'average validation accuracy: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA3im-yHIRUS",
    "outputId": "b17a27d9-7cd4-4bab-9b2f-5205a69cb8b9"
   },
   "outputs": [],
   "source": [
    "print_result(\"Logistic Regression without regularization\", y_test, log_wor_y_pred)\n",
    "print_result(\"Logistic Regression with L1 regularization\", y_test, l1_best_y_pred)\n",
    "print_result(\"Logistic Regression with L2 regularization\", y_test, l2_best_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNo35lnJi5tu"
   },
   "source": [
    "### How does the regularization parameter affect the test error? How are the learnt coefficients affected? Why might one be interested in each type of regularization?\n",
    "\n",
    "A:\n",
    "\n",
    "From our experiment, we didn't see much differences in the accuracy or error when using the best parameter in different regularization. However, the best parameter of l2 regularization is much higher than l1 regularization. \n",
    "\n",
    "We can think of that all these models can reach a limit when we find the best parameter to use. Therefore, the different bias (regularizations) we add to the model doesn't affect the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0-iB24li9vf"
   },
   "source": [
    "### Both logistic regression and linear SVM are trying to classify data points using a linear decision boundary. What is the difference between their ways to find this boundary? Why do their performances differ? Is this difference statistically significant?\n",
    "\n",
    "A:\n",
    "\n",
    "Logistic regression maximizes the conditional probability likelihood to find the decision boundary. SVM use geometric and deterministic method to separate the hyperplane and find the vectors of the margin. \n",
    "\n",
    "Therefore, SVM can yield a deterministic hyperplane to improve accuracy and reduce error rate. In which makes it more generalized and efficient. On the other hand, logistic regression is more likely to overfitting since its decision is basically relied on the dataset. In which makes it get higher accuracy more easily but lose the generality instead.\n",
    "\n",
    "Lastly, the difference in this dataset is not statistically significant since the difference is approximately 0.008. We believe there is no much difference when we can find the best parameters in each model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBJHydHTL9Yz"
   },
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW-XLAVIMOGD"
   },
   "source": [
    "### Evaluate and profile a Na¨ıve Bayes classifier: Train a GaussianNB classifier; plot the ROC curve and report the confusion matrix and calculate the accuracy, recall, precision and F-1 score of this classifier on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBINsgTLTz7U"
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_LSI, y_train)\n",
    "gnb_y_pred = gnb.predict(X_test_LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "WbZerLPyJh1Z",
    "outputId": "f17f4118-7762-41fb-f05c-cafcedcab3a2"
   },
   "outputs": [],
   "source": [
    "print_roc_curve(X_test_LSI, y_test, gnb, 'ROC curve for the GaussianNB classifiers', 'b')\n",
    "print_cf_matrix(X_test_LSI, y_test, gnb, 'GaussianNB classifiers', display_labels=root_labels)\n",
    "print_result(\"GaussianNB classifiers\", y_test, gnb_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi2AKFD8MLbd"
   },
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3J7gVUDjrh7",
    "outputId": "3faa7338-5985-4bba-8c26-2bc2e01962e8"
   },
   "outputs": [],
   "source": [
    "X_train = train['full_text']\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNbk01yCEzlK"
   },
   "outputs": [],
   "source": [
    "def stemming_sent(text): \n",
    "    # Text input is string.\n",
    "    # Returns sequence of lowercased strings(words).\n",
    "    porter = PorterStemmer()\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_list = []\n",
    "    for word in token_words:\n",
    "        stem_list.append(porter.stem(word))\n",
    "        stem_list.append(\" \")\n",
    "    # Turn array of strings into sequence\n",
    "    return ' '.join(stem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYAbDMN8E6x0",
    "outputId": "37927a1a-297f-443e-fd77-d634c9dffa1e"
   },
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir, verbose=87)\n",
    "estimators = [\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', None),\n",
    "    ('clf', None),\n",
    "    ]\n",
    "pipeline = Pipeline(estimators, memory=memory)\n",
    "param_grid = [{\n",
    "        'vect__min_df': [3,5],\n",
    "        'vect__analyzer': [lemmatize_sent, stemming_sent],\n",
    "        'reduce_dim': [TruncatedSVD(n_components=5, random_state=42),\n",
    "                       TruncatedSVD(n_components=30, random_state=42),\n",
    "                       TruncatedSVD(n_components=80, random_state=42), \n",
    "                       NMF(n_components=5, init='random', random_state=42),\n",
    "                       NMF(n_components=30, init='random', random_state=42),\n",
    "                       NMF(n_components=80, init='random', random_state=42)], \n",
    "        'clf': [svm.SVC(kernel='linear',C=100,random_state=42),\n",
    "                LogisticRegression(penalty='l1', C=100, random_state=42, solver='liblinear',max_iter=100000),\n",
    "                LogisticRegression(penalty='l2', C=100, random_state=42, solver='liblinear',max_iter=100000),\n",
    "                GaussianNB()]\n",
    "    }]\n",
    "CV = GridSearchCV(pipeline, cv=5, param_grid=param_grid, scoring='accuracy')\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK3mJdW9uUFP",
    "outputId": "d8f644e1-dd3d-4b18-ce78-e02ee5662d54"
   },
   "outputs": [],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SJiJVgjMda_"
   },
   "source": [
    "### What are the 5 best combinations? Report their performances on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgKShY2g76Hl",
    "outputId": "61e454b6-f56b-485d-c1e5-f0360451028c"
   },
   "outputs": [],
   "source": [
    "for id in range(0,len(CV.cv_results_[\"rank_test_score\"])):\n",
    "  if CV.cv_results_[\"rank_test_score\"][id] <=5:\n",
    "    print(CV.cv_results_[\"rank_test_score\"][id])\n",
    "    print(CV.cv_results_[\"params\"][id])\n",
    "    print(CV.cv_results_[\"mean_test_score\"][id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG9tQf4RFPHN"
   },
   "source": [
    "### What are the 5 best combinations? Report their performances on the testing set.\n",
    "\n",
    "(Rank)\n",
    "\n",
    "- 1 (3 models with same accuracy)\n",
    "\n",
    "  {'clf': SVC(C=100, kernel='linear', random_state=42), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 3}\n",
    "\n",
    "  {'clf': SVC(C=100, kernel='linear', random_state=42), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 5}\n",
    "\n",
    "  {'clf': LogisticRegression(C=10, max_iter=100000, penalty='l1', random_state=42, solver='liblinear'), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 3}\n",
    "\n",
    "  accuracy: 0.826984126984127\n",
    "\n",
    "- 4\n",
    "\n",
    "  {'clf': LogisticRegression(C=10, max_iter=100000, penalty='l1', random_state=42, solver='liblinear'), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 5}\n",
    "\n",
    "  accuracy: 0.8265873015873015\n",
    "\n",
    "- 5 (2 models with same accuracy)\n",
    "\n",
    "  {'clf': LogisticRegression(C=100, max_iter=100000, random_state=42, solver='liblinear'), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 3}\n",
    "\n",
    "  {'clf': LogisticRegression(C=100, max_iter=100000, random_state=42, solver='liblinear'), 'reduce_dim': TruncatedSVD(n_components=30, random_state=42), 'vect__analyzer': <function stemming_sent at 0x0000020686664EE0>, 'vect__min_df': 5}\n",
    "\n",
    "  accuracy: 0.8218253968253968\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IX-uHVWMN_T"
   },
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcmssEy7VJDs",
    "outputId": "352571d9-e13c-40ad-9549-0e9d735d788e"
   },
   "outputs": [],
   "source": [
    "train_multi, test_multi = train_test_split(df[[\"full_text\",\"leaf_label\"]], test_size=0.2)\n",
    "df['full_text'].head()\n",
    "print(\"train_multi shape:\", train_multi.shape)\n",
    "print(\"test_multi shape:\", test_multi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhMRuxnBYdkW"
   },
   "outputs": [],
   "source": [
    "X_train_multi = train_multi['full_text']\n",
    "X_test_multi = test_multi['full_text']\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "vec = CountVectorizer(stop_words='english', min_df=3)\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "X_train_lemma_m = []\n",
    "X_test_lemma_m = []\n",
    "for i in range(len(train_multi)):\n",
    "  # print(lemmatize_sent(train.iloc[i]['full_text']))\n",
    "  X_train_lemma_m.append(lemmatize_sent(train_multi.iloc[i]['full_text']))\n",
    "for i in range(len(test_multi)):\n",
    "  X_test_lemma_m.append(lemmatize_sent(test_multi.iloc[i]['full_text']))\n",
    "\n",
    "X_train_vec_m = vec.fit_transform(X_train_lemma_m)\n",
    "X_test_vec_m = vec.transform(X_test_lemma_m)\n",
    "X_train_tfidf_m = tfidf.fit_transform(X_train_vec_m)\n",
    "X_test_tfidf_m = tfidf.transform(X_test_vec_m)\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_train_LSI_m = svd.fit_transform(X_train_tfidf_m)\n",
    "X_test_LSI_m = svd.transform(X_test_tfidf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkdfPAAqNzyK"
   },
   "source": [
    "### Perform Naive Bayes classification and multiclass SVM classification (with both One VS One and One VS the rest methods described above) and report the confusion matrix and calculate the accuracy, recall, precision and F-1 score of your classifiers. How did you resolve the class imbalance issue in the One VS the rest model?\n",
    "\n",
    "- We use the library sklearn.multiclass to implement the one vs rest model. Basically, It takes the original binary svm model as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQZOxMFuYjI1",
    "outputId": "a615a216-a526-4e04-e983-4592f6efcc2b"
   },
   "outputs": [],
   "source": [
    "map_row_to_class = {\"chess\":0, \"cricket\":1, \"hockey\":2, \"soccer\":3,\n",
    "\"football\":4, \"%22forest%20fire%22\":5, \"flood\":6, \"earthquake\":7,\n",
    "\"drought\":8}\n",
    "y_train_multi = train_multi['leaf_label'].map(map_row_to_class)\n",
    "y_test_multi = test_multi['leaf_label'].map(map_row_to_class)\n",
    "\n",
    "print(y_train_multi)\n",
    "\n",
    "gnb_multi = GaussianNB()\n",
    "gnb_multi.fit(X_train_LSI_m, y_train_multi)\n",
    "gnb_multi_y_pred = gnb_multi.predict(X_test_LSI_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "aZ58fx2MYnQb",
    "outputId": "657c313b-1696-4e54-b197-94afa96af2c4"
   },
   "outputs": [],
   "source": [
    "leaf_labels = [\"chess\", \"cricket\", \"hockey\", \"soccer\",\n",
    "\"football\", \"%22forest%20fire%22\", \"flood\", \"earthquake\",\n",
    "\"drought\"]\n",
    "\n",
    "plot_confusion_matrix(gnb_multi, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with GaussianNB')\n",
    "plt.show()\n",
    "\n",
    "print_multi_result(\"Multiclass Classification with GaussianNB\", y_test_multi, gnb_multi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "834aFsagYpep"
   },
   "outputs": [],
   "source": [
    "svm_ovo = OneVsOneClassifier(svm.LinearSVC(random_state=42))\n",
    "svm_ovr = OneVsRestClassifier(svm.LinearSVC(random_state=42))\n",
    "\n",
    "# fit the model\n",
    "svm_ovo.fit(X_train_LSI_m, y_train_multi)\n",
    "svm_ovr.fit(X_train_LSI_m, y_train_multi)\n",
    "\n",
    "# predict the test data\n",
    "svm_ovo_pred = svm_ovo.predict(X_test_LSI_m)\n",
    "svm_ovr_pred = svm_ovr.predict(X_test_LSI_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yzttDNnuY0Zh",
    "outputId": "da5e37db-daf9-41a3-9edf-21c185d5ea20"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_ovo, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS One SVM')\n",
    "plt.show()\n",
    "\n",
    "plot_confusion_matrix(svm_ovr, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS Rest SVM')\n",
    "plt.show()\n",
    "\n",
    "print_multi_result(\"Multiclass Classification with One VS One SVM\", y_test_multi, svm_ovo_pred)\n",
    "print_multi_result(\"Multiclass Classification with One VS Rest SVM\", y_test_multi, svm_ovr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgl8JQi3QyDi"
   },
   "source": [
    "### Do you observe any structure in the confusion matrix? Are there distinct visible blocks on the major diagonal? What does this mean?\n",
    "\n",
    "A:\n",
    "\n",
    "Yes, there are distinct visible blocks on the major diagonal. In which means that the performance of this model should be not bad, it predict each labels correctly with a good accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUkuuBAYRcmC"
   },
   "source": [
    "### Based on your observation from the previous part, suggest a subset of labels that should be merged into a new larger label and recompute the accuracy and plot the confusion matrix. How did the accuracy change in One VS One and One VS the rest?\n",
    "\n",
    "A:\n",
    "\n",
    "Yes, we get a high error rate on the label **\"soccer\"** and **\"football\"** based on the performance. Maybe we can merge these two labels together.\n",
    "\n",
    "After merging the labels, we can find that the accuracy get increased in both the One VS One and One VS the rest.\n",
    "\n",
    "There is approximately a **0.1** increase in both the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqyqBqrBSjn0",
    "outputId": "61ca6342-1378-4788-e1c3-b5d7c85147d6"
   },
   "outputs": [],
   "source": [
    "map_row_to_class = {\"chess\":0, \"cricket\":1, \"hockey\":2, \"soccer\":3,\n",
    "\"football\":3, \"%22forest%20fire%22\":4, \"flood\":5, \"earthquake\":6,\n",
    "\"drought\":7}\n",
    "y_train_multi = train_multi['leaf_label'].map(map_row_to_class)\n",
    "y_test_multi = test_multi['leaf_label'].map(map_row_to_class)\n",
    "print(y_train_multi)\n",
    "gnb_multi = GaussianNB()\n",
    "gnb_multi.fit(X_train_LSI_m, y_train_multi)\n",
    "gnb_multi_y_pred = gnb_multi.predict(X_test_LSI_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "KDY3qxPESogh",
    "outputId": "a968f20d-a937-4d6a-ba7b-66fdc0225f88"
   },
   "outputs": [],
   "source": [
    "leaf_labels = [\"chess\", \"cricket\", \"hockey\", \"soccer and football\",\n",
    "\"%22forest%20fire%22\", \"flood\", \"earthquake\",\n",
    "\"drought\"]\n",
    "plot_confusion_matrix(gnb_multi, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with GaussianNB')\n",
    "plt.show()\n",
    "\n",
    "print_multi_result(\"Multiclass Classification with GaussianNB using new labels\", y_test_multi, gnb_multi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmlTTlikTOo4"
   },
   "outputs": [],
   "source": [
    "svm_ovo = OneVsOneClassifier(svm.LinearSVC(random_state=42))\n",
    "svm_ovr = OneVsRestClassifier(svm.LinearSVC(random_state=42))\n",
    "\n",
    "# fit the model\n",
    "svm_ovo.fit(X_train_LSI_m, y_train_multi)\n",
    "svm_ovr.fit(X_train_LSI_m, y_train_multi)\n",
    "\n",
    "# predict the test data\n",
    "svm_ovo_pred = svm_ovo.predict(X_test_LSI_m)\n",
    "svm_ovr_pred = svm_ovr.predict(X_test_LSI_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5gkMagbwTRLY",
    "outputId": "272b58ab-535b-4733-d0ef-df3f7eefb998"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_ovo, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS One SVM [new labels]')\n",
    "plt.show()\n",
    "\n",
    "plot_confusion_matrix(svm_ovr, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS Rest SVM [new labels]')\n",
    "plt.show()\n",
    "\n",
    "print_multi_result(\"Multiclass Classification with One VS One SVM [new labels]\", y_test_multi, svm_ovo_pred)\n",
    "print_multi_result(\"Multiclass Classification with One VS Rest SVM [new labels]\", y_test_multi, svm_ovr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j433eTD4UCRX"
   },
   "source": [
    "### Does class imbalance impact the performance of the classification once some classes are merged? Provide a resolution for the class imbalance and recompute the accuracy and plot the confusion matrix in One VS One and One VS the rest?.\n",
    "\n",
    "A:\n",
    "\n",
    "We set the parameter **class_weight='balanced'** from the sklearn.svm.LinearSVC. It assigns the weights of each class label so that we can implement the balanced class we want.\n",
    "\n",
    "As you can see, the accuracy of one vs rest gets increasing after dealing with the imbalance issue. However, the accuracy of one vs one doesn't get improved after dealing with the imbalance issue.\n",
    "\n",
    "There are many interpretations to explain it. One of the possible explanation might be the model already got a great accuracy which didn’t get influenced by the imbalanced class a lot. Therefore, dealing with the issue doesn't help us get a huge improve of the models. It only helps the one vs rest model get improved a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8GXpa-qtCxU"
   },
   "outputs": [],
   "source": [
    "svm_ovo = OneVsOneClassifier(svm.LinearSVC(random_state=42, class_weight='balanced'))\n",
    "svm_ovr = OneVsRestClassifier(svm.LinearSVC(random_state=42, class_weight='balanced'))\n",
    "\n",
    "# fit the model\n",
    "svm_ovo.fit(X_train_LSI_m, y_train_multi)\n",
    "svm_ovr.fit(X_train_LSI_m, y_train_multi)\n",
    "\n",
    "# predict the test data\n",
    "svm_ovo_pred = svm_ovo.predict(X_test_LSI_m)\n",
    "svm_ovr_pred = svm_ovr.predict(X_test_LSI_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "12wHf7OZtGjt",
    "outputId": "bc0631b0-632d-4147-a98f-11ab0f5a54d0"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_ovo, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS One SVM [class balanced]')\n",
    "plt.show()\n",
    "\n",
    "plot_confusion_matrix(svm_ovr, X_test_LSI_m, y_test_multi, display_labels=leaf_labels)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Multiclass Classification with One VS Rest SVM [class balanced]')\n",
    "plt.show()\n",
    "\n",
    "print_multi_result(\"Multiclass Classification with One VS One SVM [class balanced]\", y_test_multi, svm_ovo_pred)\n",
    "print_multi_result(\"Multiclass Classification with One VS Rest SVM [class balanced]\", y_test_multi, svm_ovr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTorfNqc_jGr"
   },
   "source": [
    "# Question 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTSjc6MqWYNH"
   },
   "source": [
    "### (a) Why are GLoVE embeddings trained on the ratio of co-occurrence probabilities rather than the probabilities themselves?\n",
    "\n",
    "A:\n",
    "\n",
    "Relevant relations between words could be extracted using the ratio of co-occurrence, in other words, specific properties and correlations could be extracted from the ratio, while irrelevant words, which may relate to both or neither word in the ratio, could be effectively identified. The use of simple probabilities instead of co-occurrence probabilities loses this property, making it potentially harder to differentiate between relevant and irrelevant words, as shown in the \"ice\" versus \"steam\" example in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlrh8CjFWj6w"
   },
   "source": [
    "### (b) In the two sentences: “James is running in the park.” and “James is running for the presidency.”, would GLoVE embeddings return the same vector for the word running in both cases? Why or why not?\n",
    "\n",
    "A:\n",
    "\n",
    "I would expect the GLoVE embeddings of the two to be different for any context window larger than 0, since both syntatic and semantic information greatly depends on the context (i.e. words preceding and following), which is different between the two given cases, as the target word has completely different meanings between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzvMs2jDWtEV"
   },
   "source": [
    "### (c) What do you expect for the values of,\n",
    "||GLoVE[\"queen\"] - GLoVE[\"king\"] - GLoVE[\"wife\"] + GLoVE[\"husband\"]||2,\n",
    "||GLoVE[\"queen\"] - GLoVE[\"king\"]||2 and ||GLoVE[\"wife\"] - GLoVE[\"husband\"]||2 ?Compare these values.\n",
    "\n",
    "A:\n",
    "\n",
    "I would expect ||GLoVE[\"queen\"] - GLoVE[\"king\"] - GLoVE[\"wife\"] + GLoVE[\"husband\"]||2 to be equivalent to the loss of the statement \"A king is to a queen as a husband is to a wife\", as formulated in section 4.1 of the paper, and since the relation of word analogies hold in this case, I expect the value to be somewhat relatively low.  ||GLoVE[\"queen\"] - GLoVE[\"king\"] ||2 and ||GLoVE[\"wife\"] - GLoVE[\"husband\"]||2, on the other hand, would be equivalent to the difference between \"Queen and King\" and the difference between \"Wife and Husband\", respectively, as their GLoVE embedded vectors. I expect both of these distances to be substantially larger than the first case (distance measure with all four terms), while being of similar magnitude, as to cancel out during the first case. In a vector sense, we could also characterize ||GLoVE[\"queen\"] - GLoVE[\"king\"] - GLoVE[\"wife\"] + GLoVE[\"husband\"]||2 as the magnitude of the difference between vectors GLoVE[\"queen\"] - GLoVE[\"king\"] and GLoVE[\"wife\"] - GLoVE[\"husband\"], which we would see the terms with similar magnitude (ones that satisfy the analogy relation) cancel out, leaving us with the sum of the differences between the word pairs.\n",
    "Interestingly though, as shown in the code snippet below, the actual GLoVE embeddings deviate from this assumption, and the difference between the embeddings for \"queen\" and \"king\" are substantially larger than expected, potentially due to additional meanings and usage associated with the respective words, which in turn lead to an increase in the value which pertains to the case with all four words. We believe that this result is akin to the GLoVE embedding telling us that queen to king is actually not a great analogy for wife to husband."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VV4WtS3aYufq"
   },
   "source": [
    "### (d) Given a word, would you rather stem or lemmatize the word before mapping it to its GLoVE embedding?\n",
    "\n",
    "A:\n",
    "\n",
    "Assuming that performance is a non-issue (since stemming may be required over lemmatization if this assumption does not hold), I would prefer to lemmatize the words instead of stemming them, as GLoVE works on co-occurrence, specific context or meaning of the words should be preserved, for the model to obtain a better understanding of the underlying relation between words within a vocabulary. Stemming, on the other hand, may destroy this precious information while trading for simplicity and performance, which is likely to be undesirable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTQn6rm__nrW"
   },
   "source": [
    "# Question 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = !pwd\n",
    "data_path = str(pwd[0]) + '/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGox2rKBA4I0"
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "dimension_of_glove = 300\n",
    "with open(data_path, 'r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf7ZN-yjkFTb"
   },
   "source": [
    "### (a) Describe a feature engineering process that uses GLoVE word embeddings to represent each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50suvZvsB5h0",
    "outputId": "f80f70ff-50f8-4647-c366-1fd0706fed3a"
   },
   "outputs": [],
   "source": [
    "#run this code after running definitions in Question 11\n",
    "qk=embeddings_dict[\"queen\"]-embeddings_dict[\"king\"]\n",
    "wh=embeddings_dict[\"wife\"]-embeddings_dict[\"husband\"]\n",
    "def dist(vec):\n",
    "  sum=0\n",
    "  for e in vec:\n",
    "    sum=sum+e**2\n",
    "  return sum \n",
    "print(dist(qk))\n",
    "print(dist(wh))\n",
    "print(dist(qk-wh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYDxnYTEChKT",
    "outputId": "6bc944b6-0891-4463-a4ed-11d700b5bf4c"
   },
   "outputs": [],
   "source": [
    "print(list(embeddings_dict.keys())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCfr8J2hCtVi",
    "outputId": "0df97b08-0414-486b-bdef-79ad0c8f401d"
   },
   "outputs": [],
   "source": [
    "print(list(embeddings_dict.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j61PeVGCEMxt",
    "outputId": "c2d5ea68-d8e6-4bc5-9afc-5bf51f822015"
   },
   "outputs": [],
   "source": [
    "print(df['full_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsPo5ED4F0Oq",
    "outputId": "6efacede-2c42-4584-d8b8-00e37e54f8e2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r\"\\w+|[^\\w\\s]\", df['full_text'][0], re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wbmOaTGDd9Z"
   },
   "outputs": [],
   "source": [
    "def GLoVE(rows,edict):\n",
    "  embeddings=[]\n",
    "  sums=[]\n",
    "  for row in rows:\n",
    "    words=re.findall(r\"\\w+|[^\\w\\s]\", row, re.UNICODE)\n",
    "    embedding=[]\n",
    "    sum=np.zeros(len(list(edict.values())[0]))\n",
    "    count=0\n",
    "    for word in words:\n",
    "      try:\n",
    "        sum=sum+edict[word.lower()]\n",
    "        embedding.append(edict[word.lower()])\n",
    "        count+=1\n",
    "      except:\n",
    "        pass\n",
    "    embeddings.append(embedding)\n",
    "    sums.append(sum/count)\n",
    "  return embeddings,sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39MTCrtFIEac"
   },
   "outputs": [],
   "source": [
    "embeddings,sums=GLoVE(df['full_text'],embeddings_dict)\n",
    "#print(sums[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpT0Z_wukSZU"
   },
   "source": [
    "### (b) Select a classifier model, train and evaluate it with your GLoVE-based feature. If you are doing any cross-validation, please make sure to use a limited set of options so that your code finishes running in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXWZgtxyE-Bf",
    "outputId": "79364665-30e2-4fca-c885-5c996a299431"
   },
   "outputs": [],
   "source": [
    "#Do classification either on a linear transform of <embeddings> or <sums>\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "e300tr,s300tr=GLoVE(train['full_text'],embeddings_dict)\n",
    "e300te,s300te=GLoVE(test[\"full_text\"],embeddings_dict)\n",
    "l2c = LogisticRegression(penalty='l2', random_state=9527,C=10, solver='liblinear', max_iter=100000)\n",
    "l2c.fit(s300tr, y_train)\n",
    "y_pred = l2c.predict(s300te)\n",
    "print_result(\"300d\",y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCPPpq2vh-B7"
   },
   "source": [
    "Here we observe that by aggregating all GLoVE embeddings into a single vector by taking the mean of the embedding vectors for every word in the document, we still retain enough information for our classification model (Logistic regression with l2 regularization) to efficiently differentiate between classes, achieving an accuracy of around 96.19%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JNaPZ4EE5uH"
   },
   "source": [
    "# Question 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz_yU9LtkipF"
   },
   "source": [
    "### Plot the relationship between the dimension of the pre-trained GLoVE embedding and the resulting accuracy of the model in the classification task. Describe the observed trend. Is this trend expected? Why or why not? In this part use the different sets of GLoVE vectors from the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrPhs2-8BpMY"
   },
   "outputs": [],
   "source": [
    "data_path = str(pwd[0]) + '/glove.6B.50d.txt'\n",
    "embeddings_dict50 = {}\n",
    "with open(data_path, 'r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict50[word] = vector\n",
    "data_path = str(pwd[0]) + '/glove.6B.100d.txt'\n",
    "embeddings_dict100 = {}\n",
    "with open(data_path, 'r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict100[word] = vector\n",
    "data_path = str(pwd[0]) + '/glove.6B.200d.txt'\n",
    "embeddings_dict200 = {}\n",
    "with open(data_path, 'r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings_dict200[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkSXQmXSFm-J",
    "outputId": "7ca1dd2e-7a19-444c-a6df-7989c9baae72"
   },
   "outputs": [],
   "source": [
    "print(len(embeddings_dict50.keys()))\n",
    "print(len(embeddings_dict100.keys()))\n",
    "print(len(embeddings_dict200.keys()))\n",
    "print(len(embeddings_dict.keys()))\n",
    "\n",
    "print(len(list(embeddings_dict50.values())[0]))\n",
    "print(len(list(embeddings_dict100.values())[0]))\n",
    "print(len(list(embeddings_dict200.values())[0]))\n",
    "print(len(list(embeddings_dict.values())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTjJ-1szG8SH",
    "outputId": "59c8d687-6c82-43c9-fa3f-c3b94be3d758"
   },
   "outputs": [],
   "source": [
    "#test for different GLoVE embedding lengths\n",
    "embeddings50,sums50=GLoVE(df['full_text'],embeddings_dict50)\n",
    "embeddings100,sums100=GLoVE(df['full_text'],embeddings_dict100)\n",
    "embeddings200,sums200=GLoVE(df['full_text'],embeddings_dict200)\n",
    "embeddings,sums=GLoVE(df['full_text'],embeddings_dict)\n",
    "print(sums50[0])\n",
    "print(sums100[0])\n",
    "print(sums200[0])\n",
    "print(sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EOo37TuIHfe",
    "outputId": "4816fb8c-da65-42ae-a2f0-11fb625be68d"
   },
   "outputs": [],
   "source": [
    "#do classification on all 4 dimension numbers\n",
    "print_result(\"300d\",y_test,y_pred)\n",
    "e200tr,s200tr=GLoVE(train['full_text'],embeddings_dict200)\n",
    "e200te,s200te=GLoVE(test[\"full_text\"],embeddings_dict200)\n",
    "l2c200 = LogisticRegression(penalty='l2', random_state=9527,C=10, solver='liblinear', max_iter=100000)\n",
    "l2c200.fit(s200tr, y_train)\n",
    "y_pred200 = l2c200.predict(s200te)\n",
    "print_result(\"200d\",y_test,y_pred200)\n",
    "e100tr,s100tr=GLoVE(train['full_text'],embeddings_dict100)\n",
    "e100te,s100te=GLoVE(test[\"full_text\"],embeddings_dict100)\n",
    "l2c100 = LogisticRegression(penalty='l2', random_state=9527,C=10, solver='liblinear', max_iter=100000)\n",
    "l2c100.fit(s100tr, y_train)\n",
    "y_pred100 = l2c100.predict(s100te)\n",
    "print_result(\"100d\",y_test,y_pred100)\n",
    "e50tr,s50tr=GLoVE(train['full_text'],embeddings_dict50)\n",
    "e50te,s50te=GLoVE(test[\"full_text\"],embeddings_dict50)\n",
    "l2c50 = LogisticRegression(penalty='l2', random_state=9527,C=10, solver='liblinear', max_iter=100000)\n",
    "l2c50.fit(s50tr, y_train)\n",
    "y_pred50 = l2c50.predict(s50te)\n",
    "print_result(\"50d\",y_test,y_pred50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "l1msBOzh_0VQ",
    "outputId": "43e97edf-089f-4dac-e55d-e4d586fd120a"
   },
   "outputs": [],
   "source": [
    "#plot dimension and accuracy\n",
    "plt.plot([50,100,200,300],[accuracy_score(y_test,y_pred50),accuracy_score(y_test,y_pred100),accuracy_score(y_test,y_pred200),accuracy_score(y_test,y_pred)])\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoTP9arrhygZ"
   },
   "source": [
    "We observe that the accuracy for our classification model is somewhat related to the dimension count of our GLoVE embedding, with the higher dimension embedding we get better accuracy. This is to be expected, as a higher dimension vector is able to preserve more information about the given document, especially after word embeddings are averaged over all words in a document, where individual embeddings may have its information muddled or lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z45V-bjVChT-"
   },
   "source": [
    "# Question 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJdJ4-kNlL7w"
   },
   "source": [
    "### Compare and contrast the two visualizations. Are there clusters formed in either or both of the plots? \n",
    "\n",
    "A: \n",
    "\n",
    "There are clusters formed in the GLoVE-based Embeddings Vectors but not in the randomized vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0W2kaNoHW35",
    "outputId": "d7ff8ab1-d177-4d7d-af0d-2077a72569ac"
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn\n",
    "!pip install umap-learn[plot]\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "NwmBTFiYsvYV",
    "outputId": "0e019731-ebf8-4bbf-965b-0cee42dff9ef"
   },
   "outputs": [],
   "source": [
    "#Normalized GLoVE-based embeddings of the documents with their binary labels\n",
    "fit = umap.UMAP()\n",
    "map = fit.fit_transform(s300te)\n",
    "\n",
    "scatter = plt.scatter (map[:,0], map[:,1], c = y_test)\n",
    "plt.title(\"GLoVE-based Embeddings Vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "8HczUvnuZolk",
    "outputId": "795356d6-d3a2-4ded-aaaf-dca5cdcf473d"
   },
   "outputs": [],
   "source": [
    "#Generate a set of normalized random vectors of the same dimension as GLoVE\n",
    "\n",
    "np.random.seed(9527)\n",
    "dataset = np.random.rand(len(s300te),len(s300te[0]))\n",
    "rand = fit.fit_transform(dataset) \n",
    "rand_labels = np.random.randint(2, size = rand.shape[0])\n",
    "plt.scatter(rand[:,0], rand[:,1], c = rand_labels)\n",
    "plt.title(\"Normalized Random Vectors\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
